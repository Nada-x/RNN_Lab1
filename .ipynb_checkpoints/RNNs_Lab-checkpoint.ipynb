{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbfec32-1b50-43e9-a648-c9879dc4b79c",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1eb792b-8cfc-44d8-9d1c-0bf8c403fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7705c2-42a1-4047-bbac-3a0f7465e032",
   "metadata": {},
   "source": [
    "# Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31467209-c5d3-4a4f-a79f-4a2f6e68ce85",
   "metadata": {},
   "source": [
    "### Load Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef01310-47d6-44ac-aff1-abf4da07a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets, train_labels = [], []\n",
    "\n",
    "pos = os.getcwd() + '/corpus/arabic_tweets/pos/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(pos):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(pos, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d463c-377c-4730-9398-cb5fcaa5e44b",
   "metadata": {},
   "source": [
    "### Load Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937bb606-b07a-4e7e-a83a-1ccce2b18263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the txt file negative tweet\n",
    "pos = os.getcwd() + '/corpus/arabic_tweets/neg/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(pos):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(pos, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e8e33-f28b-4402-ab6d-f4925c1db165",
   "metadata": {},
   "source": [
    "### Build a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743b5741-d234-4d22-a833-76ec742cd6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>دامك مع #غناتي ، فالك طيب 👍\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>على الفطرة السليمه.. الله يعطيه الصحة والعافية...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>📷 مشجع هلالي ينبذ العنصرية ب لافته أعدها.\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سبحان الله🌸 الحمدلله 💮 لا اله الا الله 🌿 الله ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مشاركتي في مبادراتكم الجميلة فوز وسعادة 💞\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets    Labels\n",
       "0                      دامك مع #غناتي ، فالك طيب 👍\\n  positive\n",
       "1  على الفطرة السليمه.. الله يعطيه الصحة والعافية...  positive\n",
       "2        📷 مشجع هلالي ينبذ العنصرية ب لافته أعدها.\\n  positive\n",
       "3  سبحان الله🌸 الحمدلله 💮 لا اله الا الله 🌿 الله ...  positive\n",
       "4        مشاركتي في مبادراتكم الجميلة فوز وسعادة 💞\\n  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dic = {\n",
    "    'Tweets' : train_tweets,\n",
    "    'Labels' : train_labels\n",
    "}\n",
    "\n",
    "train_corpus = pd.DataFrame(train_dic)\n",
    "train_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b046ada-13fc-45d2-9056-b4115de8e812",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "##### Explore your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6d563b-a771-43b4-8e43-3688275b1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8d4a6-89a4-47b1-bf43-08dc09b97506",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8d9fa-6fb7-4352-aadb-3abeb932c412",
   "metadata": {},
   "source": [
    "### Shuffle all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246bb815-274b-43a3-9d60-967a5864a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10a499-afa6-4d35-aa8a-53dbcae8e557",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "**Hint: remove URLs, Hashtags, alphanumeric characters, punctuation marks, stop words, extra spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d141959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_pattern = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "hashtag_pattern = r\"#\\w+\"\n",
    "mention_pattern = r\"@\\w+\"\n",
    "alphanumeric_pattern = r\"\\w*\\d\\w*\"\n",
    "punctuation_pattern = r\"[^\\w\\s]\"\n",
    "retweet_pattern = r\"^RT[\\s]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957b0161-4c2d-4f33-90a3-e8892a27455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "    return frozenset(stop_set)\n",
    "\n",
    "def process_text(text, stop_words):\n",
    "    # Remove URLs\n",
    "    text = re.sub(URL_pattern, '', text)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(hashtag_pattern, '', text)\n",
    "    \n",
    "    # Remove mention\n",
    "    text = re.sub(mention_pattern, '', text)\n",
    "\n",
    "    # Remove alphanumeric characters\n",
    "    text = re.sub(alphanumeric_pattern, '', text)\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(punctuation_pattern, '', text)\n",
    "    \n",
    "    # Remove Retweet marks\n",
    "    text = re.sub(retweet_pattern, '', text)\n",
    "\n",
    "    # Remove stop words using the provided set\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5996172",
   "metadata": {},
   "source": [
    "#### Now Clean your text using above function or implement it from scrach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e2c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0cb63",
   "metadata": {},
   "source": [
    "#### Extra: you could do stemming or lemmatization before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485120c-47f1-43e9-b6c1-cbe0a69f04c7",
   "metadata": {},
   "source": [
    "# Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "116e73af-8d88-4928-8243-6f456fc6de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160549cf-bffd-4205-a8fa-a6aa0695bcd8",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f152bfd-478f-4cdd-b17e-885d4649019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba90d2-7712-4e80-9120-c82f495b5f66",
   "metadata": {},
   "source": [
    "# Text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d2fb10-2a1a-4201-8d23-a3301dcb51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c31c7d-0375-4ef2-9f51-dccef70793d3",
   "metadata": {},
   "source": [
    "# Pad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d05e3c6-6f92-4a49-a904-f0af742ffe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d0909-8e90-4aef-9ddb-42c3597791cb",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47efb8b2-7635-48ba-a4ae-4118862e74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a35492-747b-4fea-a80c-1602ff36da21",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea5fb34-e15c-45cf-bf39-5a4c65a28705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e105a33-8de7-406f-a5fb-c1a558c7bb9d",
   "metadata": {},
   "source": [
    "# Evaulation and Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a956b35-0604-44d5-87f2-eacfb36870d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
